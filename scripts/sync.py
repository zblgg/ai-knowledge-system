#!/usr/bin/env python3
"""
çŸ¥è¯†ç®¡ç†ç³»ç»Ÿ - ç»Ÿä¸€åŒæ­¥å…¥å£ï¼ˆå¤šç»´è¡¨æ ¼ç‰ˆï¼‰

ç”¨æ³•ï¼š
    python sync.py                     # åŒæ­¥æ‰€æœ‰æ–°å¢æ–‡ä»¶
    python sync.py --file <æ–‡ä»¶è·¯å¾„>    # åŒæ­¥å•ä¸ªæ–‡ä»¶
    python sync.py --all               # å¼ºåˆ¶åŒæ­¥æ‰€æœ‰æ–‡ä»¶
    python sync.py --status            # æŸ¥çœ‹åŒæ­¥çŠ¶æ€
    python sync.py --init              # åˆå§‹åŒ–å¤šç»´è¡¨æ ¼
"""
import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from config import (
    BASE_DIR, ARCHIVE_DIR, THREADS_FILE, KNOWLEDGE_DIR, REVIEW_DIR,
    FEISHU_APP_ID, FEISHU_APP_SECRET, FEISHU_FOLDER_TOKEN
)

# åŒæ­¥çŠ¶æ€æ–‡ä»¶
SYNC_STATE_FILE = Path(__file__).parent / ".sync_state.json"
FEISHU_BITABLE_TOKEN = os.getenv("FEISHU_BITABLE_TOKEN", "")


def load_sync_state() -> dict:
    """åŠ è½½åŒæ­¥çŠ¶æ€"""
    if SYNC_STATE_FILE.exists():
        with open(SYNC_STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {"synced_files": {}, "last_sync": None}


def save_sync_state(state: dict):
    """ä¿å­˜åŒæ­¥çŠ¶æ€"""
    state["last_sync"] = datetime.now().isoformat()
    with open(SYNC_STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)


def get_all_md_files() -> list:
    """è·å–æ‰€æœ‰å¾…åŒæ­¥çš„Markdownæ–‡ä»¶"""
    files = []

    # å¯¹è¯å½’æ¡£
    if ARCHIVE_DIR.exists():
        files.extend(ARCHIVE_DIR.rglob("*.md"))

    # çº¿å¤´è¿½è¸ª
    if THREADS_FILE.exists():
        files.append(THREADS_FILE)

    # çŸ¥è¯†æ²‰æ·€
    if KNOWLEDGE_DIR.exists():
        files.extend(KNOWLEDGE_DIR.rglob("*.md"))

    # å¤ç›˜æŠ¥å‘Š
    if REVIEW_DIR.exists():
        files.extend(REVIEW_DIR.rglob("*.md"))

    # æ’é™¤æ¨¡æ¿æ–‡ä»¶
    files = [f for f in files if not f.name.startswith("_")]

    return files


def get_new_files(state: dict) -> list:
    """è·å–æ–°å¢æˆ–ä¿®æ”¹çš„æ–‡ä»¶"""
    all_files = get_all_md_files()
    synced = state.get("synced_files", {})

    new_files = []
    for f in all_files:
        f_str = str(f)
        mtime = f.stat().st_mtime

        if f_str not in synced or synced[f_str]["mtime"] < mtime:
            new_files.append(f)

    return new_files


def classify_file(file_path: Path) -> str:
    """æ ¹æ®æ–‡ä»¶è·¯å¾„åˆ†ç±»"""
    path_str = str(file_path)

    if "çº¿å¤´è¿½è¸ª" in path_str or file_path.name == "THREADS.md":
        return "threads"
    elif "å¯¹è¯å½’æ¡£" in path_str:
        return "archive"
    elif "çŸ¥è¯†æ²‰æ·€" in path_str:
        return "knowledge"
    elif "å¤ç›˜æŠ¥å‘Š" in path_str:
        return "archive"  # å¤ç›˜æŠ¥å‘Šä¹Ÿä½œä¸ºå½’æ¡£å¤„ç†
    else:
        return "knowledge"


def sync_file(file_path: Path, syncer, state: dict) -> bool:
    """åŒæ­¥å•ä¸ªæ–‡ä»¶åˆ°é£ä¹¦å¤šç»´è¡¨æ ¼"""
    from sync_feishu import (
        parse_threads_file, parse_archive_file, sync_to_feishu
    )

    file_type = classify_file(file_path)
    success = False

    try:
        if file_type == "threads":
            # çº¿å¤´æ–‡ä»¶ï¼šè§£ææ¯ä¸ªçº¿å¤´ï¼ŒåŒæ­¥åˆ°è¡¨æ ¼
            threads = parse_threads_file(file_path)
            print(f"      è§£æåˆ° {len(threads)} ä¸ªçº¿å¤´")
            synced_count = 0
            for thread in threads:
                if sync_to_feishu(syncer, "thread", thread):
                    synced_count += 1
            print(f"      åŒæ­¥ {synced_count}/{len(threads)} ä¸ªçº¿å¤´")
            success = synced_count > 0

        elif file_type == "archive":
            # å½’æ¡£æ–‡ä»¶ï¼šæå–å…ƒä¿¡æ¯ + åˆ›å»ºè¯¦æƒ…æ–‡æ¡£
            meta = parse_archive_file(file_path)

            # åˆ›å»ºè¯¦æƒ…æ–‡æ¡£
            content = file_path.read_text(encoding="utf-8")
            doc_url = syncer.create_document(file_path.stem, content)

            # åŒæ­¥å…ƒä¿¡æ¯åˆ°è¡¨æ ¼
            success = sync_to_feishu(syncer, "archive", meta, doc_url)
            if success:
                print(f"      âœ“ å½’æ¡£ç´¢å¼•å·²æ›´æ–°")

        elif file_type == "knowledge":
            # çŸ¥è¯†æ²‰æ·€ï¼šåˆ›å»ºæ–‡æ¡£ + ç´¢å¼•
            content = file_path.read_text(encoding="utf-8")

            # åˆ¤æ–­ç±»å‹
            knowledge_type = "å…¶ä»–"
            path_str = str(file_path)
            if "æ–¹æ³•è®º" in path_str:
                knowledge_type = "æ–¹æ³•è®º"
            elif "SOP" in path_str:
                knowledge_type = "SOP"
            elif "æ´è§" in path_str:
                knowledge_type = "æ´è§"

            # æå–æ‘˜è¦ï¼ˆç¬¬ä¸€æ®µéæ ‡é¢˜å†…å®¹ï¼‰
            lines = content.split('\n')
            summary = ""
            for line in lines:
                line = line.strip()
                if line and not line.startswith('#') and not line.startswith('---'):
                    summary = line[:200]
                    break

            # åˆ›å»ºè¯¦æƒ…æ–‡æ¡£
            doc_url = syncer.create_document(file_path.stem, content)

            # åŒæ­¥åˆ°è¡¨æ ¼
            data = {
                "æ ‡é¢˜": file_path.stem,
                "ç±»å‹": knowledge_type,
                "æ‘˜è¦": summary
            }
            success = sync_to_feishu(syncer, "knowledge", data, doc_url)
            if success:
                print(f"      âœ“ çŸ¥è¯†ç´¢å¼•å·²æ›´æ–°")

    except Exception as e:
        print(f"      âœ— åŒæ­¥å¤±è´¥: {e}")
        return False

    # æ›´æ–°çŠ¶æ€
    if success:
        state["synced_files"][str(file_path)] = {
            "mtime": file_path.stat().st_mtime,
            "synced_at": datetime.now().isoformat(),
            "type": file_type
        }

    return success


def main():
    parser = argparse.ArgumentParser(description="çŸ¥è¯†ç®¡ç†ç³»ç»ŸåŒæ­¥å·¥å…·")
    parser.add_argument("--file", "-f", help="åŒæ­¥å•ä¸ªæ–‡ä»¶")
    parser.add_argument("--all", "-a", action="store_true", help="å¼ºåˆ¶åŒæ­¥æ‰€æœ‰æ–‡ä»¶")
    parser.add_argument("--status", "-s", action="store_true", help="æŸ¥çœ‹åŒæ­¥çŠ¶æ€")
    parser.add_argument("--init", "-i", action="store_true", help="åˆå§‹åŒ–å¤šç»´è¡¨æ ¼")
    parser.add_argument("--check", "-c", action="store_true", help="æ£€æŸ¥é…ç½®")
    args = parser.parse_args()

    # æ£€æŸ¥é…ç½®
    if args.check:
        print("ğŸ“‹ é…ç½®æ£€æŸ¥ï¼š")
        print(f"   FEISHU_APP_ID: {'âœ“' if FEISHU_APP_ID else 'âœ— æœªé…ç½®'}")
        print(f"   FEISHU_APP_SECRET: {'âœ“' if FEISHU_APP_SECRET else 'âœ— æœªé…ç½®'}")
        print(f"   FEISHU_FOLDER_TOKEN: {'âœ“' if FEISHU_FOLDER_TOKEN else 'âœ— æœªé…ç½®'}")
        print(f"   FEISHU_BITABLE_TOKEN: {'âœ“' if FEISHU_BITABLE_TOKEN else 'âœ— æœªé…ç½®'}")
        return

    # æŸ¥çœ‹çŠ¶æ€
    if args.status:
        state = load_sync_state()
        synced = state.get("synced_files", {})
        print(f"ğŸ“Š åŒæ­¥çŠ¶æ€")
        print(f"   æœ€ååŒæ­¥: {state.get('last_sync', 'ä»æœª')}")
        print(f"   å·²åŒæ­¥æ–‡ä»¶: {len(synced)} ä¸ª")
        print()

        if synced:
            print("æœ€è¿‘åŒæ­¥çš„æ–‡ä»¶ï¼š")
            sorted_files = sorted(
                synced.items(),
                key=lambda x: x[1].get("synced_at", ""),
                reverse=True
            )[:5]
            for f, info in sorted_files:
                print(f"   {Path(f).name} [{info.get('type', 'unknown')}]")
                print(f"      æ—¶é—´: {info.get('synced_at', 'N/A')}")
        return

    # æ£€æŸ¥å¿…è¦é…ç½®
    if not FEISHU_APP_ID or not FEISHU_APP_SECRET or not FEISHU_FOLDER_TOKEN:
        print("âŒ é£ä¹¦é…ç½®ä¸å®Œæ•´")
        print("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡ï¼š")
        print("     export FEISHU_APP_ID='your_app_id'")
        print("     export FEISHU_APP_SECRET='your_app_secret'")
        print("     export FEISHU_FOLDER_TOKEN='your_folder_token'")
        return

    # åˆå§‹åŒ–åŒæ­¥å™¨
    from sync_feishu import FeishuSync
    syncer = FeishuSync()
    syncer.get_tenant_access_token()

    # åˆå§‹åŒ–å¤šç»´è¡¨æ ¼
    if args.init:
        print("ğŸ“Š åˆå§‹åŒ–å¤šç»´è¡¨æ ¼...")
        if syncer.init_bitable():
            print("\nâœ… åˆå§‹åŒ–æˆåŠŸï¼")
            print(f"   è¯·æ·»åŠ ç¯å¢ƒå˜é‡: export FEISHU_BITABLE_TOKEN=\"{syncer.bitable_token}\"")
        else:
            print("âŒ åˆå§‹åŒ–å¤±è´¥")
        return

    # æ£€æŸ¥å¤šç»´è¡¨æ ¼é…ç½®
    if not FEISHU_BITABLE_TOKEN:
        print("âŒ æœªé…ç½® FEISHU_BITABLE_TOKEN")
        print("   è¯·å…ˆè¿è¡Œ: python sync.py --init")
        return

    syncer.bitable_token = FEISHU_BITABLE_TOKEN
    syncer.get_all_table_ids()

    state = load_sync_state()

    # åŒæ­¥å•ä¸ªæ–‡ä»¶
    if args.file:
        file_path = Path(args.file)
        if not file_path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return

        print(f"ğŸ“¤ åŒæ­¥æ–‡ä»¶: {file_path.name}")
        if sync_file(file_path, syncer, state):
            save_sync_state(state)
            print("âœ… åŒæ­¥å®Œæˆ")
        else:
            print("âŒ åŒæ­¥å¤±è´¥")
        return

    # åŒæ­¥æ‰€æœ‰æ–‡ä»¶
    if args.all:
        files = get_all_md_files()
        print(f"ğŸ“¤ å¼ºåˆ¶åŒæ­¥æ‰€æœ‰æ–‡ä»¶ ({len(files)} ä¸ª)")
    else:
        files = get_new_files(state)
        if not files:
            print("âœ… æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦åŒæ­¥")
            return
        print(f"ğŸ“¤ åŒæ­¥æ–°å¢/ä¿®æ”¹çš„æ–‡ä»¶ ({len(files)} ä¸ª)")

    success = 0
    for f in files:
        print(f"\n   ğŸ“„ {f.name}")
        if sync_file(f, syncer, state):
            success += 1

    save_sync_state(state)
    print(f"\nâœ… åŒæ­¥å®Œæˆ: {success}/{len(files)} æˆåŠŸ")


if __name__ == "__main__":
    main()
